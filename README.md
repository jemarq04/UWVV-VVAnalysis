# UWVV/VVAnalysis
-----------------

This project is meant to take in ntuples produced from [UWVV](https://github.com/jemarq04/UWVV) and process them for analysis. There are scripts
available to skim ntuples, merge files, and plot distributions.

Note that this repository is still in-progress.

## Setup

Eventually, this will be set up automatically by UWVV. Until then, run the following commands.

This project has been tested within `CMSSW_15_0_14`. To create a fresh environment, run the following:

```bash
cmsrel CMSSW_15_0_14
cd CMSSW_15_0_14/src
cmsenv
```

Once you have an environment prepared, make sure it's activated (with `cmsenv`) and run the following:

```bash
cd $CMSSW_BASE/src
git clone git@github.com:jemarq04/UWVV-VVAnalysis UWVV/VVAnalysis
scram build UWVV/VVAnalysis
```

Finally, make a copy of `config/template.cfg`:

```bash
# Inside UWVV/VVAnalysis
cp config/template.cfg config/$USER.cfg
```

Make sure to edit this file with your settings.

## Usage

### Skimming

There are a few scripts within [`scripts/`](scripts/) that help skim UWVV ntuples. The most important is [`scripts/skim.py`](scripts/skim.py). This
script will use the information stored in [`json/`](json/) to determine cuts, triggers, and aliases and apply these cuts to the input file(s). To see
available options, run `skim.py --help`, which is pasted below.

```
usage: skim.py [-h] [-a ANALYSIS] [-y YEAR] [-t TRIGGER] [-o OUTFILE] [-g] [-v] [--json-dir JSON_DIR] (-i INFILES [INFILES ...] | -I INPUT_FILE_LIST)

optional arguments:
  -h, --help            show this help message and exit
  -a ANALYSIS, --analysis ANALYSIS
                        name of analysis (default: ZZ4l)
  -y YEAR, --year YEAR  year for analysis (default: 2022)
  -t TRIGGER, --trigger TRIGGER
                        trigger set to apply (default: MonteCarlo)
  -o OUTFILE, --outfile OUTFILE
                        output file (default: output<YEAR>.root)
  -g, --save-gen        save gen trees (default: False)
  -v, --verbose         print during skimming (default: False)
  --json-dir JSON_DIR   directory for JSON files (default: UWVV/VVAnalysis/json)
  -i INFILES [INFILES ...], --infiles INFILES [INFILES ...]
                        input file (default: None)
  -I INPUT_FILE_LIST, --input-file-list INPUT_FILE_LIST
                        file that lists input files, one per line (default: None)
```

An example command would be:

```bash
skim.py -a ZZ4l -y 2022 -t MonteCarlo -i /path/to/file.root -o MyOutput.root
```

This is helpful for skimming one file at a time, but becomes tedious if you need to skim an entire set of files (i.e. those generated by submitting
UWVV jobs through CRAB). To help with that, there are two options: [`scripts/farmout_skim.py`](scripts/farmout_skim.py) and
[`scripts/multi_skim.py`](scripts/multi_skim.py). Once again, call the command with `--help` to get more information on how they are run.

Both scripts will do the same thing, but with slight differences. The `farmout_skim.py` script will use the UW cluster's `farmoutAnalysisJobs` command
to submit one job per file through HTCondor. These can be monitored with `condor_q`. However, the `multi_skim.py` script will run skimming locally
using multiple cores. This will often be faster, but will require keeping a terminal open (or using `tmux`).

Both scripts will read the information from the relevant `ntuples.json` file, depending on the analysis and year given as input. To see what format
this JSON file needs to be in, look at [`json/README.md`](json/README.md).

#### Making the input files

If you used CRAB to submit UWVV jobs, you likely have many output files for many output datasets. To help with listing all the files for skimming,
there is [`scripts/make_json.py`](scripts/make_json.py). By providing the root directory with the ntuples, the relevant `ntuples.json` file will be
created depending on the given analysis and year. This requires the `data.json` and `montecarlo.json` files, which are explained in
[`json/README.md`](json/README.md).

### Merging

Work in progress.

### Plotting

Work in progress.
